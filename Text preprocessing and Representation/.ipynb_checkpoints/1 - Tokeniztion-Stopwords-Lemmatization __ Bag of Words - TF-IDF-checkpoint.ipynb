{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183620dd-1944-4453-8242-3ebdffec300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\erfan\\anaconda3\\envs\\my2\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\erfan\\anaconda3\\envs\\my2\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\erfan\\anaconda3\\envs\\my2\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\erfan\\anaconda3\\envs\\my2\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca182c37-948a-4739-b246-06b3e5807296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\erfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\erfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\erfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt_tab') # word_tokenize\n",
    "nltk.download('stopwords') # stopwords\n",
    "nltk.download('wordnet') # WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da455c9-9140-4408-a37a-38d3a73abc06",
   "metadata": {},
   "source": [
    "### Sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff43c218-745b-49af-9c48-34723ccfa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Cats were chasing the mice while the dogs were barking loudly in the yard.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfafc355-b38a-44a9-baeb-2efa0f65dcb3",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "010a7d8a-44a5-4a53-a5fc-63d7a0118b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      " ['cats', 'were', 'chasing', 'the', 'mice', 'while', 'the', 'dogs', 'were', 'barking', 'loudly', 'in', 'the', 'yard', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text.lower())\n",
    "print(\"Tokens:\\n\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd541f57-8582-48bf-a174-d24440acf0ed",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86f127ef-9d88-4c3c-95ea-310cbab2f885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words with less english meaning (removed words): ['were', 'the', 'while', 'the', 'were', 'in', 'the']\n",
      "\n",
      "words with more english meaning (kept words)   : ['cats', 'chasing', 'mice', 'dogs', 'barking', 'loudly', 'yard', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered = [w for w in tokens if w not in stopwords.words('english')] # a list comprehension for accessing each word in tokens\n",
    "removed = [w for w in tokens if w in stopwords.words('english')] # a list comprehension for accessing each word in tokens\n",
    "\n",
    "print(\"words with less english meaning (removed words):\",removed)\n",
    "print(\"\\nwords with more english meaning (kept words)   :\",filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782c23c-505e-48b4-bcc4-2c32501948cd",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7f2f05e-ffff-44df-a2b5-8a158ac1e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stemming ['cat', 'chase', 'mice', 'dog', 'bark', 'loudli', 'yard', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(w) for w in filtered]\n",
    "\n",
    "print(\"after stemming\", stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06172ed-297d-4dcc-834c-03f12874fad2",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f90cbe08-6f7d-46ac-a4c9-f19122d9e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized: ['cat', 'chasing', 'mouse', 'dog', 'barking', 'loudly', 'yard', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in filtered]\n",
    "print(\"Lemmatized:\", lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76839b-84bb-4b11-a7cd-125bda824450",
   "metadata": {},
   "source": [
    "# Feature Representation in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb9536-d03f-468c-b3ab-6077c32e48e3",
   "metadata": {},
   "source": [
    "### 1. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e89fbda0-4ad5-443f-821c-d09883f7a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning' 'love' 'machine' 'nlp']\n",
      "[[0 1 0 1]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [\"I love NLP\", \"I love machine learning\"]\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb28e29-6776-425b-a548-a9aee507891f",
   "metadata": {},
   "source": [
    "### 2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "832267aa-d1ad-4aae-8a81-27969ee6cd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning' 'love' 'machine' 'nlp']\n",
      "[[0.         0.57973867 0.         0.81480247]\n",
      " [0.6316672  0.44943642 0.6316672  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "docs = [\"I love NLP\", \"I love machine learning\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4f3bb-7189-4b2b-b219-36b9b0c41b64",
   "metadata": {},
   "source": [
    "### Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34d2cd19-7d54-4033-9d37-888b85e1b57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Accuracy: 0.4444444444444444\n",
      "TF-IDF Accuracy: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# some tweets\n",
    "texts = [\n",
    "    # Positive reviews (1)\n",
    "    \"I love this movie\",\n",
    "    \"Amazing experience, I enjoyed it\",\n",
    "    \"Fantastic acting and story\",\n",
    "    \"Great film with beautiful cinematography\",\n",
    "    \"The music and emotions were perfect\",\n",
    "    \"Wonderful direction and amazing visuals\",\n",
    "    \"A masterpiece of storytelling\",\n",
    "    \"Heartwarming and inspiring movie\",\n",
    "    \"Brilliant performance by the cast\",\n",
    "    \"Loved every minute of it\",\n",
    "    \"The ending was powerful and emotional\",\n",
    "    \"Such a fun and entertaining film\",\n",
    "    \"The characters felt real and relatable\",\n",
    "    \"A beautiful and touching experience\",\n",
    "    \"An absolute joy to watch\",\n",
    "\n",
    "    # Negative reviews (0)\n",
    "    \"This film was terrible\",\n",
    "    \"I hate this movie\",\n",
    "    \"Worst movie ever\",\n",
    "    \"The plot was boring and predictable\",\n",
    "    \"Bad acting and weak script\",\n",
    "    \"I almost fell asleep while watching\",\n",
    "    \"Too long and painfully slow\",\n",
    "    \"Poor direction and horrible pacing\",\n",
    "    \"The ending made no sense\",\n",
    "    \"Awful sound quality and editing\",\n",
    "    \"Disappointing and overhyped\",\n",
    "    \"Nothing interesting happened\",\n",
    "    \"I regret spending time on this\",\n",
    "    \"The movie was just a waste of time\"\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  # 15 positives\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0       # 15 negatives\n",
    "]\n",
    "# --- Bag-of-Words ---\n",
    "bow = CountVectorizer()\n",
    "X_bow = bow.fit_transform(texts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "model_bow = MultinomialNB() # Naive Bayes\n",
    "model_bow.fit(X_train, y_train)\n",
    "pred_bow = model_bow.predict(X_test)\n",
    "print(\"BoW Accuracy:\", accuracy_score(y_test, pred_bow))\n",
    "\n",
    "# --- TF-IDF ---\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(texts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "model_tfidf = MultinomialNB() # Naive Bayes\n",
    "model_tfidf.fit(X_train, y_train)\n",
    "pred_tfidf = model_tfidf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8df200db-6346-4294-a118-ee48b3cfb3aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'absolute'), (1, 'acting'), (2, 'almost'), (3, 'amazing'), (4, 'an'), (5, 'and'), (6, 'asleep'), (7, 'awful'), (8, 'bad'), (9, 'beautiful'), (10, 'boring'), (11, 'brilliant'), (12, 'by'), (13, 'cast'), (14, 'characters'), (15, 'cinematography'), (16, 'direction'), (17, 'disappointing'), (18, 'editing'), (19, 'emotional'), (20, 'emotions'), (21, 'ending'), (22, 'enjoyed'), (23, 'entertaining'), (24, 'ever'), (25, 'every'), (26, 'experience'), (27, 'fantastic'), (28, 'fell'), (29, 'felt'), (30, 'film'), (31, 'fun'), (32, 'great'), (33, 'happened'), (34, 'hate'), (35, 'heartwarming'), (36, 'horrible'), (37, 'inspiring'), (38, 'interesting'), (39, 'it'), (40, 'joy'), (41, 'just'), (42, 'long'), (43, 'love'), (44, 'loved'), (45, 'made'), (46, 'masterpiece'), (47, 'minute'), (48, 'movie'), (49, 'music'), (50, 'no'), (51, 'nothing'), (52, 'of'), (53, 'on'), (54, 'overhyped'), (55, 'pacing'), (56, 'painfully'), (57, 'perfect'), (58, 'performance'), (59, 'plot'), (60, 'poor'), (61, 'powerful'), (62, 'predictable'), (63, 'quality'), (64, 'real'), (65, 'regret'), (66, 'relatable'), (67, 'script'), (68, 'sense'), (69, 'slow'), (70, 'sound'), (71, 'spending'), (72, 'story'), (73, 'storytelling'), (74, 'such'), (75, 'terrible'), (76, 'the'), (77, 'this'), (78, 'time'), (79, 'to'), (80, 'too'), (81, 'touching'), (82, 'visuals'), (83, 'was'), (84, 'waste'), (85, 'watch'), (86, 'watching'), (87, 'weak'), (88, 'were'), (89, 'while'), (90, 'with'), (91, 'wonderful'), (92, 'worst')]\n",
      "  (0, 43)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 48)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 26)\t1\n",
      "  (1, 22)\t1\n",
      "  (1, 39)\t1\n",
      "  (2, 27)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 72)\t1\n",
      "  (3, 32)\t1\n",
      "  (3, 30)\t1\n",
      "  (3, 90)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 15)\t1\n",
      "  (4, 5)\t1\n",
      "  (4, 76)\t1\n",
      "  (4, 49)\t1\n",
      "  (4, 20)\t1\n",
      "  (4, 88)\t1\n",
      "  (4, 57)\t1\n",
      "  (5, 3)\t1\n",
      "  (5, 5)\t1\n",
      "  (5, 91)\t1\n",
      "  :\t:\n",
      "  (23, 50)\t1\n",
      "  (23, 68)\t1\n",
      "  (24, 5)\t1\n",
      "  (24, 7)\t1\n",
      "  (24, 70)\t1\n",
      "  (24, 63)\t1\n",
      "  (24, 18)\t1\n",
      "  (25, 5)\t1\n",
      "  (25, 17)\t1\n",
      "  (25, 54)\t1\n",
      "  (26, 51)\t1\n",
      "  (26, 38)\t1\n",
      "  (26, 33)\t1\n",
      "  (27, 77)\t1\n",
      "  (27, 65)\t1\n",
      "  (27, 71)\t1\n",
      "  (27, 78)\t1\n",
      "  (27, 53)\t1\n",
      "  (28, 48)\t1\n",
      "  (28, 76)\t1\n",
      "  (28, 52)\t1\n",
      "  (28, 83)\t1\n",
      "  (28, 78)\t1\n",
      "  (28, 41)\t1\n",
      "  (28, 84)\t1\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(bow.get_feature_names_out())))\n",
    "print(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76f57ac7-6648-49c3-b312-88eb0525f04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'absolute'), (1, 'acting'), (2, 'almost'), (3, 'amazing'), (4, 'an'), (5, 'and'), (6, 'asleep'), (7, 'awful'), (8, 'bad'), (9, 'beautiful'), (10, 'boring'), (11, 'brilliant'), (12, 'by'), (13, 'cast'), (14, 'characters'), (15, 'cinematography'), (16, 'direction'), (17, 'disappointing'), (18, 'editing'), (19, 'emotional'), (20, 'emotions'), (21, 'ending'), (22, 'enjoyed'), (23, 'entertaining'), (24, 'ever'), (25, 'every'), (26, 'experience'), (27, 'fantastic'), (28, 'fell'), (29, 'felt'), (30, 'film'), (31, 'fun'), (32, 'great'), (33, 'happened'), (34, 'hate'), (35, 'heartwarming'), (36, 'horrible'), (37, 'inspiring'), (38, 'interesting'), (39, 'it'), (40, 'joy'), (41, 'just'), (42, 'long'), (43, 'love'), (44, 'loved'), (45, 'made'), (46, 'masterpiece'), (47, 'minute'), (48, 'movie'), (49, 'music'), (50, 'no'), (51, 'nothing'), (52, 'of'), (53, 'on'), (54, 'overhyped'), (55, 'pacing'), (56, 'painfully'), (57, 'perfect'), (58, 'performance'), (59, 'plot'), (60, 'poor'), (61, 'powerful'), (62, 'predictable'), (63, 'quality'), (64, 'real'), (65, 'regret'), (66, 'relatable'), (67, 'script'), (68, 'sense'), (69, 'slow'), (70, 'sound'), (71, 'spending'), (72, 'story'), (73, 'storytelling'), (74, 'such'), (75, 'terrible'), (76, 'the'), (77, 'this'), (78, 'time'), (79, 'to'), (80, 'too'), (81, 'touching'), (82, 'visuals'), (83, 'was'), (84, 'waste'), (85, 'watch'), (86, 'watching'), (87, 'weak'), (88, 'were'), (89, 'while'), (90, 'with'), (91, 'wonderful'), (92, 'worst')]\n",
      "  (0, 48)\t0.49006036262699626\n",
      "  (0, 77)\t0.5243009045503789\n",
      "  (0, 43)\t0.6963830860019157\n",
      "  (1, 39)\t0.48446649734491243\n",
      "  (1, 22)\t0.5439454373841699\n",
      "  (1, 26)\t0.48446649734491243\n",
      "  (1, 3)\t0.48446649734491243\n",
      "  (2, 72)\t0.5771811273113059\n",
      "  (2, 5)\t0.26354891260346536\n",
      "  (2, 1)\t0.5140679558354433\n",
      "  (2, 27)\t0.5771811273113059\n",
      "  (3, 15)\t0.4738142266957242\n",
      "  (3, 9)\t0.42200394198240987\n",
      "  (3, 90)\t0.4738142266957242\n",
      "  (3, 30)\t0.38524395997017963\n",
      "  (3, 32)\t0.4738142266957242\n",
      "  (4, 57)\t0.4662247042740825\n",
      "  (4, 88)\t0.4662247042740825\n",
      "  (4, 20)\t0.4662247042740825\n",
      "  (4, 49)\t0.4662247042740825\n",
      "  (4, 76)\t0.2919215952283014\n",
      "  (4, 5)\t0.2128846700388289\n",
      "  (5, 82)\t0.5133255915264603\n",
      "  (5, 16)\t0.45719484755727247\n",
      "  (5, 91)\t0.5133255915264603\n",
      "  :\t:\n",
      "  (23, 21)\t0.435355921234836\n",
      "  (23, 76)\t0.30606029038952176\n",
      "  (24, 18)\t0.48745724385140293\n",
      "  (24, 63)\t0.48745724385140293\n",
      "  (24, 70)\t0.48745724385140293\n",
      "  (24, 7)\t0.48745724385140293\n",
      "  (24, 5)\t0.22257974226594748\n",
      "  (25, 54)\t0.6729017667410899\n",
      "  (25, 17)\t0.6729017667410899\n",
      "  (25, 5)\t0.30725628493724855\n",
      "  (26, 33)\t0.5773502691896258\n",
      "  (26, 38)\t0.5773502691896258\n",
      "  (26, 51)\t0.5773502691896258\n",
      "  (27, 53)\t0.4789072155811267\n",
      "  (27, 78)\t0.42654002651727263\n",
      "  (27, 71)\t0.4789072155811267\n",
      "  (27, 65)\t0.4789072155811267\n",
      "  (27, 77)\t0.36056517076894845\n",
      "  (28, 84)\t0.4513642091078423\n",
      "  (28, 41)\t0.4513642091078423\n",
      "  (28, 78)\t0.4020087721756057\n",
      "  (28, 83)\t0.3398282753757995\n",
      "  (28, 52)\t0.3669905323825992\n",
      "  (28, 76)\t0.28261685565735617\n",
      "  (28, 48)\t0.3176350954503626\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(tfidf.get_feature_names_out())))\n",
    "print(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770896d-1390-4b53-86af-e0295e1be12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36b039-9f0c-4edf-b62f-164fffbde03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
